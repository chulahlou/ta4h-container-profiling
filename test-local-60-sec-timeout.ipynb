{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9562f075-de6f-49a3-a1c8-65f95976cb95",
   "metadata": {},
   "source": [
    "### Client\n",
    "\n",
    "This notebook contains the client application code as well as the code to performance profile the server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa893add-b531-4143-a5fa-8af4ac95b54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "import requests\n",
    "import json \n",
    "import threading\n",
    "from typing import Dict, List, Optional\n",
    "import numpy as np\n",
    "\n",
    "URI = \"http://localhost:5000\"\n",
    "# URI = \"http://chu-healthcare-dns-name.eastus.azurecontainer.io:5000\"\n",
    "SYNC_ROUTE = \"/text/analytics/v3.1/entities/health\"\n",
    "ASYNC_SUBMIT_ROUTE = \"/text/analytics/v3.1/entities/health/jobs\"\n",
    "ASYNC_STATUS_ROUTE = \"/text/analytics/v3.1/entities/health/jobs/{}\"\n",
    "\n",
    "class InferenceCall(threading.Thread): \n",
    "    def __init__(\n",
    "        self, \n",
    "        call_server_sync: Optional[bool] = True, \n",
    "        batch_size: Optional[int] = 1, \n",
    "    ): \n",
    "        super().__init__()\n",
    "        self.batched_payload = InferenceCall.make_batched_payload(batch_size)\n",
    "        self.call_server_sync = call_server_sync\n",
    "        self.batch_size = batch_size\n",
    "        self.latency = None\n",
    "        self.throughput = None \n",
    "        self.success = None\n",
    "        self.status_code = None \n",
    "        \n",
    "    @staticmethod\n",
    "    def make_batched_payload(batch_size: int) -> Dict: \n",
    "        payload = {\n",
    "          \"documents\": [\n",
    "            {\n",
    "              \"text\": \"Patient doesn't suffer from high blood pressure. \" * 102,\n",
    "              \"id\": f\"{idx}\",\n",
    "              \"language\": \"en\",\n",
    "              \"isLanguageDefaulted\": True,\n",
    "              \"isLanguageFinalized\": False,\n",
    "              \"isAutoLanguageDetectionEnabled\": False\n",
    "            } for idx in range(batch_size)\n",
    "          ]\n",
    "        }\n",
    "        return payload \n",
    "    \n",
    "    def run(self): \n",
    "        if self.call_server_sync: \n",
    "            st = time.time()\n",
    "            response = requests.post(URI + SYNC_ROUTE, json=self.batched_payload)\n",
    "            en = time.time() \n",
    "            status_code = response.status_code\n",
    "        else: \n",
    "            st = time.time() \n",
    "            submit_response = requests.post(URI + ASYNC_SUBMIT_ROUTE, json=self.batched_payload)\n",
    "            job_uid = submit_response.headers[\"Operation-Location\"].split('/')[-1]\n",
    "            status_response = requests.get(URI + ASYNC_STATUS_ROUTE.format(job_uid))\n",
    "            status = status_response.json()[\"status\"].lower() \n",
    "            while status != \"succeeded\":\n",
    "                time.sleep(0.01)\n",
    "                status_response = requests.get(URI + ASYNC_STATUS_ROUTE.format(job_uid))\n",
    "                status = status_response.json()[\"status\"].lower() \n",
    "                if status not in ['notstarted', 'running', 'succeeded']: \n",
    "                    print(status)\n",
    "                    break\n",
    "            en = time.time() \n",
    "            if status == \"succeeded\": \n",
    "                status_code = 200\n",
    "            else: \n",
    "                status_code = 500\n",
    "        self.latency = en - st\n",
    "        self.throughput = self.batch_size / self.latency \n",
    "        self.status_code = status_code \n",
    "        self.success = status_code == 200\n",
    "    \n",
    "    \n",
    "class Client: \n",
    "    def __init__(\n",
    "        self, \n",
    "        num_concurrent_calls: Optional[int] = 1, \n",
    "        call_server_sync: Optional[bool] = True, \n",
    "        batch_size: Optional[int] = 1, \n",
    "    ): \n",
    "        super().__init__()\n",
    "        self.num_concurrent_calls = num_concurrent_calls\n",
    "        self.call_server_sync = call_server_sync\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.calls = [InferenceCall(call_server_sync=call_server_sync, batch_size=batch_size) for _ in range(num_concurrent_calls)]\n",
    "        self.latency = None\n",
    "        self.throughput = None \n",
    "        self.success_rate = None\n",
    "        self.success = None\n",
    "        self.statuses = None\n",
    "        \n",
    "    def execute(self): \n",
    "        st = time.time()\n",
    "        for call in self.calls: \n",
    "            call.start() \n",
    "        for call in self.calls: \n",
    "            call.join()\n",
    "        en = time.time() \n",
    "        self.latency = en - st\n",
    "        self.success = all([call.success for call in self.calls])\n",
    "        num_successes = sum([call.success for call in self.calls])\n",
    "        self.success_rate =  num_successes / len(self.calls)\n",
    "        self.throughput = num_successes * self.batch_size / self.latency\n",
    "        self.statuses = {} \n",
    "        for call in self.calls: \n",
    "            if call.status_code not in self.statuses: \n",
    "                self.statuses[call.status_code] = 0 \n",
    "            self.statuses[call.status_code] += 1\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29010097-658b-464d-9b58-8ffd4f6884ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test call wasnot successful.\n",
      "- Latency: 60.59368 seconds\n",
      "- Throughput: 0.09902022450095017 TPS\n",
      "- Success Rate: 12.00%\n"
     ]
    }
   ],
   "source": [
    "c = Client(num_concurrent_calls=50, call_server_sync=True, batch_size=1)\n",
    "c.execute()\n",
    "\n",
    "print(f\"The test call was{'' if c.success else 'not'} successful.\")\n",
    "print(f\"- Latency: {c.latency:.5f} seconds\")\n",
    "print(f\"- Throughput: {c.throughput} TPS\")\n",
    "print(f\"- Success Rate: {100 * c.success_rate:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8745f7f6-efb7-4cae-bc4d-ecd79fddcc77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391f6c10-b1cb-43d4-b34f-09d53732d781",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
