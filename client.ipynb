{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9562f075-de6f-49a3-a1c8-65f95976cb95",
   "metadata": {},
   "source": [
    "### Client\n",
    "\n",
    "This notebook contains the client application code as well as the code to performance profile the server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa893add-b531-4143-a5fa-8af4ac95b54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "import requests\n",
    "import json \n",
    "import threading\n",
    "from typing import Dict, List, Optional\n",
    "import numpy as np\n",
    "\n",
    "# URI = \"http://localhost:5000\"\n",
    "URI = \"http://chu-healthcare-dns-name.eastus.azurecontainer.io:5000\"\n",
    "SYNC_ROUTE = \"/text/analytics/v3.1/entities/health\"\n",
    "ASYNC_SUBMIT_ROUTE = \"/text/analytics/v3.1/entities/health/jobs\"\n",
    "ASYNC_STATUS_ROUTE = \"/text/analytics/v3.1/entities/health/jobs/{}\"\n",
    "\n",
    "class InferenceCall(threading.Thread): \n",
    "    def __init__(\n",
    "        self, \n",
    "        call_server_sync: Optional[bool] = True, \n",
    "        batch_size: Optional[int] = 1, \n",
    "    ): \n",
    "        super().__init__()\n",
    "        self.batched_payload = InferenceCall.make_batched_payload(batch_size)\n",
    "        self.call_server_sync = call_server_sync\n",
    "        self.batch_size = batch_size\n",
    "        self.latency = None\n",
    "        self.throughput = None \n",
    "        self.success = None\n",
    "        self.status_code = None \n",
    "        \n",
    "    @staticmethod\n",
    "    def make_batched_payload(batch_size: int) -> Dict: \n",
    "        payload = {\n",
    "          \"documents\": [\n",
    "            {\n",
    "              \"text\": \"Patient doesn't suffer from high blood pressure. \" * 102,\n",
    "              \"id\": f\"{idx}\",\n",
    "              \"language\": \"en\",\n",
    "              \"isLanguageDefaulted\": True,\n",
    "              \"isLanguageFinalized\": False,\n",
    "              \"isAutoLanguageDetectionEnabled\": False\n",
    "            } for idx in range(batch_size)\n",
    "          ]\n",
    "        }\n",
    "        return payload \n",
    "    \n",
    "    def run(self): \n",
    "        if self.call_server_sync: \n",
    "            st = time.time()\n",
    "            response = requests.post(URI + SYNC_ROUTE, json=self.batched_payload)\n",
    "            en = time.time() \n",
    "            status_code = response.status_code\n",
    "        else: \n",
    "            st = time.time() \n",
    "            submit_response = requests.post(URI + ASYNC_SUBMIT_ROUTE, json=self.batched_payload)\n",
    "            job_uid = submit_response.headers[\"Operation-Location\"].split('/')[-1]\n",
    "            status_response = requests.get(URI + ASYNC_STATUS_ROUTE.format(job_uid))\n",
    "            status = status_response.json()[\"status\"].lower() \n",
    "            while status != \"succeeded\":\n",
    "                time.sleep(0.01)\n",
    "                status_response = requests.get(URI + ASYNC_STATUS_ROUTE.format(job_uid))\n",
    "                status = status_response.json()[\"status\"].lower() \n",
    "                if status not in ['notstarted', 'running', 'succeeded']: \n",
    "                    print(status)\n",
    "                    break\n",
    "            en = time.time() \n",
    "            if status == \"succeeded\": \n",
    "                status_code = 200\n",
    "            else: \n",
    "                status_code = 500\n",
    "        self.latency = en - st\n",
    "        self.throughput = self.batch_size / self.latency \n",
    "        self.status_code = status_code \n",
    "        self.success = status_code == 200\n",
    "    \n",
    "    \n",
    "class Client: \n",
    "    def __init__(\n",
    "        self, \n",
    "        num_concurrent_calls: Optional[int] = 1, \n",
    "        call_server_sync: Optional[bool] = True, \n",
    "        batch_size: Optional[int] = 1, \n",
    "    ): \n",
    "        super().__init__()\n",
    "        self.num_concurrent_calls = num_concurrent_calls\n",
    "        self.call_server_sync = call_server_sync\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.calls = [InferenceCall(call_server_sync=call_server_sync, batch_size=batch_size) for _ in range(num_concurrent_calls)]\n",
    "        self.latency = None\n",
    "        self.throughput = None \n",
    "        self.success_rate = None\n",
    "        self.success = False\n",
    "        self.statuses = None\n",
    "        \n",
    "    def execute(self): \n",
    "        st = time.time()\n",
    "        for call in self.calls: \n",
    "            call.start() \n",
    "        for call in self.calls: \n",
    "            call.join()\n",
    "        en = time.time() \n",
    "        self.latency = en - st\n",
    "        self.success = all([call.success for call in self.calls])\n",
    "        num_successes = sum([call.success for call in self.calls])\n",
    "        self.success_rate =  num_successes / len(self.calls)\n",
    "        self.throughput = num_successes * self.batch_size / self.latency\n",
    "        self.statuses = {} \n",
    "        for call in self.calls: \n",
    "            if call.status_code not in self.statuses: \n",
    "                self.statuses[call.status_code] = 0 \n",
    "            self.statuses[call.status_code] += 1\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29010097-658b-464d-9b58-8ffd4f6884ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Client(num_concurrent_calls=2, call_server_sync=False, batch_size=1)\n",
    "c.execute()\n",
    "\n",
    "print(f\"The test call was{'' if c.success else 'not'} successful.\")\n",
    "print(f\"- Latency: {c.latency:.5f} seconds\")\n",
    "print(f\"- Throughput: {c.throughput} TPS\")\n",
    "print(f\"- Success Rate: {100 * c.success_rate:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8745f7f6-efb7-4cae-bc4d-ecd79fddcc77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70e599e-b499-4ed6-b439-216eddf125c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_concurrent_experiment(\n",
    "    call_server_sync: bool, \n",
    "    batch_size: int, \n",
    "    num_concurrent_calls: List[int], \n",
    "    num_trials: int,\n",
    "    partial_data_name: str, \n",
    "): \n",
    "    data = {ncc: [] for ncc in num_concurrent_calls}\n",
    "    for _ in range(num_trials):\n",
    "        for ncc in num_concurrent_calls: \n",
    "            trial = Client(num_concurrent_calls=ncc, call_server_sync=call_server_sync, batch_size=batch_size)\n",
    "            trial.execute()\n",
    "            data[ncc].append(\n",
    "                {\n",
    "                    'latency': trial.latency, \n",
    "                    'throughput': trial.throughput, \n",
    "                    'success': trial.success,\n",
    "                    'success_rate': trial.success_rate,\n",
    "                    'statuses': trial.statuses,\n",
    "                }\n",
    "            )\n",
    "            json.dump(data, open(f'{partial_data_name}.json', 'w'), indent=4)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e3ef05-0b79-4607-a932-434383df4b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_concurrent_calls = [i for i in range(1, 25)] + [25 + 5*k for k in range(6)]\n",
    "num_trials = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8abf86-dc12-456d-aea0-25cde028480e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = run_concurrent_experiment(\n",
    "    call_server_sync=True, \n",
    "    batch_size=1, \n",
    "    num_concurrent_calls=num_concurrent_calls, \n",
    "    num_trials=num_trials, \n",
    "    partial_data_name=\"sync_endpoint_20_trials_bs_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac3a275-4d23-4f56-85ba-26a02f00df49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data2 = run_concurrent_experiment(\n",
    "    call_server_sync=False, \n",
    "    batch_size=1, \n",
    "    num_concurrent_calls=num_concurrent_calls, \n",
    "    num_trials=num_trials, \n",
    "    partial_data_name=\"async_endpoint_20_trials_bs_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74af466-b7ba-4725-b498-3f129cfc395a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data3 = run_concurrent_experiment(\n",
    "    call_server_sync=True, \n",
    "    batch_size=5, \n",
    "    num_concurrent_calls=num_concurrent_calls, \n",
    "    num_trials=num_trials, \n",
    "    partial_data_name=\"sync_endpoint_20_trials_bs_5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d60e33-d7b9-47c0-bcf3-f1d52263cae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data4 = run_concurrent_experiment(\n",
    "    call_server_sync=False, \n",
    "    batch_size=5, \n",
    "    num_concurrent_calls=num_concurrent_calls, \n",
    "    num_trials=num_trials, \n",
    "    partial_data_name=\"async_endpoint_20_trials_bs_5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbec9c5d-4ab6-424d-95ed-4029e020ece0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a2ffe7-74f6-49ed-b1df-2257bc3662fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33444180-deb0-4f73-9cad-e7933814f5b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5148685-2d74-4559-9669-02df2649ef1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391f6c10-b1cb-43d4-b34f-09d53732d781",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
